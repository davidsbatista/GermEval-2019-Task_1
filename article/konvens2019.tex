%
% File acl2019.tex
%
%% Based on the style files for ACL 2018, NAACL 2018/19, which were
%% Based on the style files for ACL-2015, with some improvements
%%  taken from the NAACL-2016 style
%% Based on the style files for ACL-2014, which were, in turn,
%% based on ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009,
%% EACL-2009, IJCNLP-2008...
%% Based on the style files for EACL 2006 by
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{acl2019}
\usepackage{times}
\usepackage{latexsym}
\usepackage{verbatim}
\usepackage{url}
\usepackage{fixltx2e}
\usepackage{graphicx}

\aclfinalcopy % Uncomment this line for the final submission
%\def\aclpaperid{***} %  Enter the acl Paper ID here

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\newcommand\BibTeX{B\textsc{ib}\TeX}

\title{COMTRAVO-DS team at GermEval 2019 shared task on hierarchical classification of blurbs}

\author{David S. Batista \\
  Comtravo GmbH \\
  {\tt david.batista@comtravo.com} \\\And
  Matti Lyra \\
  Comtravo GmbH \\
  {\tt matti.lyra@comtravo.com} \\}


\date{}

\begin{document}
\maketitle

\begin{abstract}
We present a detailed description of the systems used for the GermEval'19 Task 1
on hierarchical classification of blurbs. The challenges in this type of document
classification are related with capturing the correct hierarchical structure of
each document to label.
We developed two systems, with which we generated two different submissions
achieving the 13th place out of 19th submissions for Sub-Task A and 11th place
out of 19th submissions for Sub-Task B. We describe in detailed these two systems
pointing out the advantages and advantages of each and lay down some foundations
for some possibly future work on how to improve this results.
\end{abstract}




\section{Introduction}

This paper describes the approach taken for the GermEval'19 task 1 taken by the
Comtravo data-science team. The task aimed at developing systems to tackle the
task of multi-label hierarchical classification of text. We took two distinct
approaches, one based on a local classifier strategy, where different classifiers
are trained according to the hierarchical structure of the label space. Another
approach uses a single classifier which tries to naively predict the label
hierarchy for each sample.

This paper is organized as follows, in Section~\ref{task} we describe task in
detail and give a description of the dataset provided. In Section~\ref{hierarchical-clf}
we describe some of the proposed approaches in the literature to performer
hierarchical document classification. In Section~\ref{system} we describe the
system we build to tackle the task and the approaches taken. Section~\ref{experiments}
details the experiments done and the results, finally in Section~\ref{future} we
outline some future work and ideas.



\section{Task}\label{task}

The GermEval 2010 Shared Task on hierarchical classification of blurbs challenges
involved the classification of books into genres given a book's blurb i.e., a
short textual description of the book. The competition contained two sub-tasks:

\begin{itemize}

\item Sub-Task A: classify German books into one or multiple most general writing
genres. Therefore, it can be considered a multi-label classification task. In
total, there are 8 classes that can be assigned to a book.

\item Sub-Task B: targets hierarchical multi-label classification into multiple
writing genres. In addition to the very general writing genres, additional
genres of different specificity can be assigned to a book.

\end{itemize}


\subsection{Dataset}

The dataset made available for this task contains 3 levels and it's considered
a hierarchically multi-label since any example can be can assigned to more than
one class at any given level of the hierarchy. The hierarchy contains a total of
343 classes distinct classes, and in overall there are 16 627 samples available
for training, XX XXX for development and XX XXX for testing.

The Tables~\ref{quantitivy-analysis-train} contain a detailed statistical description of
the dataset provided organized by set, i.e.: train, dev and test.

% every child has exacly one parent, The underlying hierarchy is a forest.
% hierarchy-tree
% imbalence of classes ?
% taxonomy or tree ?
% Whether the taxonomy is organized into a tree or a DAG influences the degree of difficulty of
% the underlying hierarchical classification problem


\begin{table}
\small
\begin{center}
\begin{tabular}{|l|r|}
\hline\centering\textbf{Training set}  &                        \\
\hline
Avg. lenght of blurb (tokens)              &  96.78             \\
Std. deviation $\sigma$ (tokens)           &  39.63             \\
Avg. lenght of blurb (sentences)           &  6.55              \\
Std. deviation $\sigma$ (sentences)        &  2.76              \\
\hline
Total number of genres                     &  343               \\
Possible genres per level (1;2;3)          &  8; 93; 242        \\
Avg. genres per per blurb                  &  3.1               \\
Std. deviation $\sigma$                    &  1.36              \\
Avg. genres per blurb at level (1;2;3)     &  1.06; 1.34; 0.69  \\
Std. deviation $\sigma$                    &  0.27; 0.76; 0.79  \\
\hline
Avg. blurb per co-occurrence               &  6.48              \\
Co-Occurrence std. deviation               & 35.90              \\
\hline
Nr. samples with leaf nodes at:            &                    \\
 - Level 1                                 & 1.9\% (311)        \\
 - Level 2                                 & 44,6\% (7.422)     \\
 - Level 3                                 & 53,5\% (8.894)     \\
\hline
\end{tabular}
\end{center}
\caption{\label{quantitivy-analysis-train}Quantitative analysis of the training dataset.}
\end{table}


\begin{table}
\small
\begin{center}
\begin{tabular}{|l|r|}
\hline\centering\textbf{Development set}  &             \\
\hline
Avg. lenght of blurb (tokens)              &   98.71        \\
Std. deviation $\sigma$ (tokens)           &   46.29        \\
Avg. lenght of blurb (sentences)           &   6.68         \\
Std. deviation $\sigma$ (sentences)        &   3.80         \\
\hline
Total number of genres                     &                   \\
Possible genres per level (1;2;3)          &                   \\
Avg. genres per per blurb                  &   3.1             \\
Std. deviation $\sigma$                    &   1.39            \\
Avg. genres per blurb at level (1;2;3)     &   1.07;1.35;0.69  \\
Std. deviation $\sigma$                    &   0.27;0.80;0.79  \\
\hline
Avg. blurb per co-occurrence               &   3.08            \\
Co-Occurrence std. deviation               &   8.19            \\
\hline
Nr. samples with leaf nodes at:            &                   \\
 - Level 1                                 &    1.6\% (34 )    \\
 - Level 2                                 &    44.8\% (932 )  \\
 - Level 3                                 &    53.6\% (1113)  \\
\hline
\end{tabular}
\end{center}
\caption{\label{quantitivy-analysis-train}Quantitative analysis of the development dataset.}
\end{table}


\begin{table}
\small
\begin{center}
\begin{tabular}{|l|r|}
\hline\centering\textbf{Test set}  &         \\
\hline
Avg. lenght of blurb (tokens)              &  96.91             \\
Std. deviation $\sigma$ (tokens)           &  39.83             \\
Avg. lenght of blurb (sentences)           &  6.55              \\
Std. deviation $\sigma$ (sentences)        &  2.62              \\
\hline
\end{tabular}
\end{center}
\caption{\label{quantitivy-analysis-dev}Quantitative analysis of the test dataset.}
\end{table}


% TODO: grafico com histogram de freqs. para tokens/sentence/genre ?
% TODO: Avg. blurb per co-occurrence ?













\section{Hierarchical Document Classification}\label{hierarchical-clf}


Several real-world classification problems are naturally cast within a hierarchy,
where the labels to be predicted are organized in an hierarchy, typically as
tree or a DAG (Direct Acyclic Graph).

\ \newline
\textbf{TODO: give a few examples}
\ \newline

There are different strategies to approach this problem and within the context
of the GermEval'19 Task 1 we explored two strategies: local classifier and a
global classifier.


\subsection{Local Classifier}

The local classifier strategy is one way to approach the hierarchical document classification task
and it was first proposed, to the best of our knowledge, in the seminal work of Koller and
Sahami~\shortcite{Koller:1997:HCD:645526.657130}, it is also sometimes referred to as top-down
approach in the literature.

There are different approaches, based on the idea of a local classifier, depending on how they use
the local information and devise a strategy to build several classifiers~\cite{Silla:2011:SHC:1937796.1937884}.


\subsubsection{A classifier per node} % Local Classifier Per Node Approach
The \textit{local classifier per node approach} consists in training one binary classifier for each
node in the hierarchy tree, where a node is every possible label in the hierarchy tree.

For instance, having classes 1, 2 and 3 in the first level, one classifier can be trained with
samples belonging to class 1 as positive and classes 2 and 3 as negative, a similar approach is then
followed for the the other classes and lower levels in the hierarchy. There are different strategies
on how to select the positive and negative classes (see~\cite{}).

During prediction a top-down strategy is applied, the output of each binary classifier will be a
prediction of whether or not a given test sample belongs to the classifierâ€™s predicted class. This
approach is naturally multi-label since it is possible to predict multiple labels per class level.

This approach however is prone to class-membership inconsistency, consider having again in the first
level classes 1, 2 and 3, and in the second level, for instance, classes 1.1, 1.2, since the
classifiers for nodes 1 and 1.1 are independently trained, one can classify a sample as belonging to
classes 1.2 and 1.1 but not to class 1. This approach should also be complemented by a
post-processing method that tries to correct the prediction inconsistency.


\subsubsection{A classifier per parent node} % Local Classifier Per Parent Node Approach
In \textit{a per parent node approach}, for each parent node in the hierarchy tree, a multi-class
classifier is trained to classify the probability of a given sample belonging to each of the parent's
child nodes. A parent node is in this case every label in the hierarchy-tree which has one or more
child labels.

Given a test sample, first the top-level classifier is applied, then for every top-level
predicted class (e.g., class 2 and 3) we apply it's child classifiers, e.g.: a classifier
trained to predicted every 2.x classes and another for 3.x classes, and so one until we reach the
last level.

Note that the sub-classifiers were trained only with the children of classes 2 and 3, therefore
this approach avoids the problem of making inconsistent predictions and respects the constrains
of class-membership defined by the hierarchy-tree.


\subsubsection{A classifier per level} % Local Classifier Per Level Approach
The \textit{local classifier per level} approach consists of training one multi-class classifier
for each level of the hierarchy-tree. When a new test sample is presented we get the output of the
classifiers from each level and use this information as the final classification.

This approach however is prone to class-membership inconsistency, since different classifiers are
trained for each level of the hierarchy. For instance, it's possible to have has outputs for the
first-level classes 2 and 3, and then classes 1.1 and 1.2 at the second-level, and class 3.1.1
at the third-level, which generates an inconsistent classification. This approach should also
be complemented by a post-processing method that tries to correct the prediction inconsistency.

One common error to all strategies in the local classifier and the top-down class-prediction
approach is the propagation of errors downwards the hierarchy.



\subsection{Global Classifier}

Another type of strategy is to learn a classifier than can globally learn to
output the predictions for each level in the hierarchical structure. This is
done by flattening and hierarchical structure and leveraging on the labels
co-occurrence.


\section{Systems Developed}\label{system}

We developed two systems implementing the following approaches: a classifier per
parent node (parent-node), and global classifier by exploring the
labels co-occurrence.


\subsection{Local Classifier}

We employed a parent per parent approach, which has the advantage of not being
prone to hierarchy inconsistency errors. We need to train classifiers for each
parent node, except for the leaf nodes. For the Level 2 we don't need to train
any classifier since it contains only leaf nodes, plus some nodes on Level 1
are already leaf nodes.

According to Table~\ref{quantitivy-analysis-train} the first level has 8 possible
labels, which means that the parent node of the first level (i.e, the Root node)
needs to be trained in a multi-label fashion and predict over 8 classes. Each of
these 8 classes represents a parent node of some child classes on the
second level of the hierarchy. So for Level 1 we need to train eight multi-label
classifiers where the labels are the child`s of each parent in the root level.
Finally, for Level 2, we train 42 classifiers only, since according to the
hierarchy-tree some labels in this level are already leaf nodes. In total we
trained 51 classifiers distributed by different levels as described in
Table~\ref{parent-per-node-classifiers}.

\begin{table}[!h]
\begin{center}
\begin{tabular}{|l|r|}
\hline\centering\textbf{Level}  &  \textbf{Nr. Parent Nodes}    \\
\hline
Root              &  1       \\
Level 1           &  8       \\
Level 2           &  42      \\
\hline
Total Classifiers & 51       \\
\hline
\end{tabular}
\end{center}
\caption{\label{parent-per-node-classifiers}Number of parent nodes per level in the hierarchy.}
\end{table}

% TODO:
% - advantages and disadvantages of this method? errors propagate
% - no need to apply a post-processing cleaning stop to enforce the hierarchical structure


\subsection{Global Classifier}

The global classifier needs to be a multi-label classifier targeting a label
space with a total of 343 classes.

\begin{comment}
\begin{figure}[h]
\centering
    \includegraphics[width=8cm]{global_classifier_nn.png}
    \caption{Convolutional Neural Networks for sentence classification with weight initialization. (adapted from )}
    \label{fig:mesh1}
\end{figure}


\begin{figure}[h]
    \centering
    \includegraphics[width=8cm]{global_classifier_init.png}
    \caption{Weight initialization matrix (adapted from )}
    \label{fig:mesh1}
\end{figure}
\end{comment}


% TODO:
% - advantages and disadvantages of this method?
% - single classifer
% - need to apply a post-processing cleaning to enforce the hierarchical structure



\section{Experiments and Results}\label{experiments}

In this section we describe the experimental setup and results for the two
devised strategies for tackling both subtasks.

\subsection{Results on the Development Set}

For both strategies we randomly split the training set into two sub-sets, of
70\%, 30\%, for training and testing/parameter search respectively. The biggest
portion (70\%) was used to train the classifiers, and the remaining portion (30\%)
to evaluate each set selected parameters the one which yielded the best results.

Then the complete training data was used to train a classifier with the best
parameters, and this classifier was evaluated on the development set. Results
reported in this section are all in regard to the development set.


\subsubsection{Local classifier per node}

For the local classifier (\textit{local\_clf\_logit\_cnn}) we tried different root
classifiers and selected for Level 1 and Level 2 a Convolutional Neural Network.
Note that one can see this root classifier as attending the Sub-Task A only.

For the root level classifier we also tried the following approaches:
Logistic Regression with TF-IDF weighted vectors~\cite{},
ConvNets~\cite{kim-2014-convolutional},
LSTM~\cite{Hochreiter:1997:LSM:1246443.1246450}
Bag-of-Tricks~\cite{joulin-etal-2017-bag}.

\begin{comment}
We also explored different methods of tokenisation

The best results were achieved with the following classifiers configuration.

For the root node we trained a logistic regression with TF-IDF weighted vectors
in a one-versus-rest scenario using the scikit-learn 0.21.1~\cite{Pedregosa:2011:SML:1953048.2078195}.

% class_weight='balanced', solver='sag', max_iter=50000
% The "balanced" mode uses the values of y to automatically adjust weights inversely proportional to
% class frequencies in the input data as ``n_samples / (n_classes * np.bincount(y))``.

We pre-processed the data by first tokenising the blurbs into sentences, and then
from sentences into tokens. We consider the title of the book a sentence. We used
the german sentence tokeniser, and the \textit {word\_punkt\_tokenizer} both available
on NLTLK 3.4.1~\cite{Bird:2009:NLP:1717171}, also, we only considered alphanumeric
tokens, i.e., all punctuation tokens were discarded.

% What else did we tried? % de_stemmer = GermanStemmer() % stop-words ?

We preformed a parameter search, on 3 folds over the training set, varying following parameters:

\begin{itemize}
\item token n-grams: \{(1), (1,2),(1,3)\}
\item token lowercase: \{True, False\}
\item norm: \{l1, l2\}
\item regularization C: \{0.1, 10, 100, 300\}
\end{itemize}

\end{comment}

\begin{table}[!h]
\begin{center}
\begin{tabular}{|l|r|r|r|}
\hline\centering\textbf{Method}  & \textbf{Precision} &  \textbf{Recall} &  \textbf{F\textsubscript{1}}\\
\hline
 Logit (TF-IDF) & 0.8211 & 0.8359 & 0.8284 \\
 ConvNets       & 0.8542 & 0.7879 & 0.8197 \\
 bi-LSTM        & 0.8062 & 0.7987 & 0.8024 \\
 Bag-of-Tricks  & 0.3787 & 0.6717 & 0.4843 \\
\hline
\end{tabular}
\end{center}
\caption{\label{devset-results} Results for different classifiers on the Sub-Task A on the development set.}
\end{table}

This root classifier is also the one that reports the results for Sub-Task A
using the local classifier strategy.










\begin{comment}

For Level 1 and 2 in the hierarchy tree we trained in total 50 classifiers based
the convolutional neural networks sentence classification model
from~\citet{kim-2014-convolutional}.

We implemented the variation of the proposed architecture based on pre-trained
embeddings which are fine-tuned during learning, and we used the public
available German fastText embeddings trained on Wikipedia, of dimension 300
and obtained using the skip-gram model as described in~\citet{bojanowski-etal-2017-enriching}
with default parameters.

% tokenisation = {'low': True, 'simple': True, 'stop': True}

We used rectified linear units in the activation functions of the 1D convolutions,
filter windows (i.e., n-grams) of size 1 and 2 with 300 feature maps each and a
dropout rate of 0.5.

Training is done with the Adam optimizer~\cite{journals/corr/KingmaB14} over
shuffled mini-batches of size 16 for 10 epochs and using 33\% of the data for validation.
The neural network was implemented in Keras 2.2.4 with Tensorflow 1.13.1 backend.


We then applied the best classifiers and parameters on the dev set and run the evaluation.
Table~\ref{devset-results} shows the results for both tasks with the system described above on the
development set.

\end{comment}

\begin{table}[!h]
\begin{center}
\begin{tabular}{|l|r|r|r|}
\hline\centering\textbf{Method}  & \textbf{Precision} &  \textbf{Recall} &  \textbf{F\textsubscript{1}}\\
\hline
 Conf\_1 & 0.7151 & 0.5330 & 0.6108 \\
 Conf\_2 & 0.7144 & 0.5303 & 0.6087 \\
 Conf\_3 & 0.7219 & 0.5235 & 0.6069 \\
 Conf\_4 & 0.7274 & 0.5085 & 0.5986 \\
\hline
\end{tabular}
\end{center}
\caption{\label{devset-results} Results for Sub-Task B for different configurations of the ConvNets-based classifier for Levels 1 and 2 of the hierarchy, using the best classifier for the Root Level from Table 5.}
\end{table}

\begin{comment}
1)
n_grams=[1, 2]; feature_maps=300; epochs=5; batch_size=16; pre-trainned embeddings=de-wiki-fasttext-300d-1M
Precision	0.7151
Recall	0.533
F1	0.6108

2)
n_grams=[1, 2, 3], feature_maps=200
Precision	0.7144
Recall	0.5303
F1	0.6087

3)
n_grams=[1, 2, 3, 5, 7], feature_maps=300
Precision	0.7219
Recall	0.5235
F1	0.6069

4)
n_grams=[3, 5, 7, 10], feature_maps=256
Precision	0.7274
Recall	0.5085
F1	0.5986

\end{comment}






\subsection{Test Results}

We applied the systems



% Comtravo-DS	Comtravo-DS__local_clf_logit_cnn
% subtask_a - Comtravo-DS	Comtravo-DS__local_clf_logit_cnn	13	0.7178	0.8144	0.8255	0.8199	0.943
% subtask_b - Comtravo-DS__local_clf_logit_cnn	11	0.1924	0.7042	0.5274	0.6031	1	0.943
\begin{table}[!h]
\begin{center}
\begin{tabular}{|l|r|r|r|}
\hline\centering\textbf{Task}  & \textbf{Precision} &  \textbf{Recall} &  \textbf{F\textsubscript{1}}\\
\hline
 Sub-Task A   &  0.8144 & 0.8255 & 0.8199 \\
 Sub-Task B   &  0.7042 & 0.5274 & 0.6031 \\
\hline
\end{tabular}
\end{center}
\caption{\label{devset-results} Best achieved results on the development set for both Sub-Tasks A and B with the parent per node classifier.}
\end{table}


% Comtravo-DS__global_clf_cnn
% - Comtravo-DS__global_clf_cnn	17	0.7183	0.7761	0.7839	0.78390.7839	0.9925
% - Comtravo-DS__global_clf_cnn	13	0.1751	0.5672	0.5185	0.5418	0.9363	0.9986
\begin{table}[!h]
\begin{center}
\begin{tabular}{|l|r|r|r|}
\hline\centering\textbf{Task}  & \textbf{Precision} &  \textbf{Recall} &  \textbf{F\textsubscript{1}}\\
\hline
 Sub-Task A   &  0.7761 & 0.7839 & 0.7839 \\
 Sub-Task B   &  0.5672 & 0.5185 & 0.5418 \\
\hline
\end{tabular}
\end{center}
\caption{\label{devset-results} Best achieved results on the development set for both Sub-Tasks A and B with the global classifier.}
\end{table}










\section{Future Work}\label{future}

% other features, release date, author's name

\begin{comment}
\citet{kurata-etal-2016-improved} proposed a novel neural network initialization method to
treat some of the neurons in the final hidden layer as dedicated neurons for each pattern of label
co-occurrence These dedicated neurons are initialized to connect to the corresponding co-occurring
labels with stronger weights than to others.

When the labels form a hierarchy, they share a hypernymâ€“hyponym relation. When multiple
 labels are assigned to the text, if it is explicitly labeled by a subclass it must also implicitly
 include all of the its super- classes.
The co-occurrence between subclasses and superclasses as labels for the input text contains
information we would like to leverage to improve multi-label classification using a neural network.
\end{comment}







\ \newline
\textbf{TODO:}
\ \newline




\section*{Acknowledgments}

\ \newline

\bibliography{konvens2019.bib}
\bibliographystyle{acl_natbib}

\begin{comment}

\appendix

\section{Appendices}
\label{sec:appendix}
Appendices are material that can be read, and include lemmas, formulas, proofs, and tables that are not critical to the reading and understanding of the paper.
Appendices should be \textbf{uploaded as supplementary material} when submitting the paper for review. Upon acceptance, the appendices come after the references, as shown here. Use
\verb|\appendix| before any appendix section to switch the section
numbering over to letters.


\section{Supplemental Material}
\label{sec:supplemental}
Submissions may include non-readable supplementary material used in the work and described in the paper. Any accompanying software and/or data should include licenses and documentation of research review as appropriate. Supplementary material may report preprocessing decisions, model parameters, and other details necessary for the replication of the experiments reported in the paper. Seemingly small preprocessing decisions can sometimes make a large difference in performance, so it is crucial to record such decisions to precisely characterize state-of-the-art methods.

Nonetheless, supplementary material should be supplementary (rather
than central) to the paper. \textbf{Submissions that misuse the supplementary
material may be rejected without review.}
Supplementary material may include explanations or details
of proofs or derivations that do not fit into the paper, lists of
features or feature templates, sample inputs and outputs for a system,
pseudo-code or source code, and data. (Source code and data should
be separate uploads, rather than part of the paper).

The paper should not rely on the supplementary material: while the paper
may refer to and cite the supplementary material and the supplementary material will be available to the
reviewers, they will not be asked to review the
supplementary material.
\end{comment}

\end{document}
